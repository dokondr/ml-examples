{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import gzip\n",
    "import sys\n",
    "import pickle as pkl\n",
    "\n",
    "#from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create, train and evaluate Bi-LSTM on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1337)  # for reproducibility\n",
    "DATA_PATH = \"bi-lstm-data/\"\n",
    "EMBEDDINGS_PATH = DATA_PATH+'embeddings.pkl.gz'\n",
    "TRAIN_SET_PATH = DATA_PATH+'train_set.pkl.gz'\n",
    "TEST_SET_PATH = DATA_PATH+'test_set.csv'\n",
    "MODEL_PATH = DATA_PATH+'bi-lstm-model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train set embeddings\n",
    "f = gzip.open(EMBEDDINGS_PATH, 'rb')\n",
    "embeddings = pkl.load(f)\n",
    "f.close()\n",
    "\n",
    "label2Idx = embeddings['label2Idx']\n",
    "wordEmbeddings = embeddings['wordEmbeddings']\n",
    "caseEmbeddings = embeddings['caseEmbeddings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse label mapping\n",
    "idx2Label = {v: k for k, v in label2Idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-MISC': 0, 'B-LOC': 1, 'I-PER': 2, 'I-ORG': 3, 'O': 4, 'I-MISC': 5, 'B-PER': 6, 'I-LOC': 7, 'B-ORG': 8} \n",
      "---\n",
      " {0: 'B-MISC', 1: 'B-LOC', 2: 'I-PER', 3: 'I-ORG', 4: 'O', 5: 'I-MISC', 6: 'B-PER', 7: 'I-LOC', 8: 'B-ORG'}\n"
     ]
    }
   ],
   "source": [
    "print(label2Idx,'\\n---\\n', idx2Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all train set\n",
    "f = gzip.open(TRAIN_SET_PATH, 'rb')\n",
    "data = pkl.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[12558, 1, 1445, 1, 1, 1, 18468, 1, 6566, 1, 1],\n",
       " [3, 4, 3, 4, 4, 0, 1, 4, 2, 4, 4],\n",
       " [1, 4, 1, 4, 4, 4, 4, 4, 8, 4, 4]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0] # word2Idx, case2Idx, label2Idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((75272, 300), (8, 8))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordEmbeddings.shape, caseEmbeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bi-LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "words_input (InputLayer)        (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "casing_input (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 300)    22581600    words_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 8)      64          casing_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, 308)    0           embedding_1[0][0]                \n",
      "                                                                 embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, None, 100)    143600      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, None, 9)      909         bidirectional_1[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 22,726,173\n",
      "Trainable params: 144,509\n",
      "Non-trainable params: 22,581,664\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_out = len(label2Idx)\n",
    "\n",
    "words_input = Input(shape=(None,), dtype='int32', name='words_input')\n",
    "words = Embedding(input_dim=wordEmbeddings.shape[0], output_dim=wordEmbeddings.shape[1],  \n",
    "                  weights=[wordEmbeddings], trainable=False)(words_input)\n",
    "\n",
    "casing_input = Input(shape=(None,), dtype='int32', name='casing_input')\n",
    "casing = Embedding(output_dim=caseEmbeddings.shape[1], input_dim=caseEmbeddings.shape[0], \n",
    "                   weights=[caseEmbeddings], trainable=False)(casing_input)\n",
    "\n",
    "output = concatenate([words, casing])\n",
    "output = Bidirectional(LSTM(50, return_sequences=True, dropout=0.25, \n",
    "                            recurrent_dropout=0.25))(output)\n",
    "output = TimeDistributed(Dense(n_out, activation='softmax'))(output)\n",
    "\n",
    "#Create our model and compile it using Nadam optimizer with categorical cross-entropy for sparse y-labels\n",
    "model = Model(inputs=[words_input, casing_input], outputs=[output])\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='nadam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1(predictions, correct, idx2Label): \n",
    "    \"\"\"Compute F1 score = (precision * recall) / (precision + recall). \n",
    "    \"\"\"\n",
    "    label_pred = []    \n",
    "    for sentence in predictions:\n",
    "        label_pred.append([idx2Label[element] for element in sentence])\n",
    "        \n",
    "    label_correct = []    \n",
    "    for sentence in correct:\n",
    "        label_correct.append([idx2Label[element] for element in sentence])\n",
    "                \n",
    "    prec = compute_precision(label_pred, label_correct)\n",
    "    rec = compute_precision(label_correct, label_pred)\n",
    "    \n",
    "    f1 = 0\n",
    "    if (rec+prec) > 0:\n",
    "        f1 = 2.0 * prec * rec / (prec + rec);\n",
    "        \n",
    "    return prec, rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_precision(guessed_sentences, correct_sentences):\n",
    "    \"\"\"Compute precision\"\"\"\n",
    "    \n",
    "    assert(len(guessed_sentences) == len(correct_sentences))\n",
    "    correctCount = 0\n",
    "    count = 0\n",
    "\n",
    "    for sentenceIdx in range(len(guessed_sentences)):\n",
    "        guessed = guessed_sentences[sentenceIdx]\n",
    "        correct = correct_sentences[sentenceIdx]\n",
    "        assert(len(guessed) == len(correct))\n",
    "        idx = 0\n",
    "        while idx < len(guessed):\n",
    "            if guessed[idx][0] == 'B': # A new chunk starts\n",
    "                count += 1\n",
    "                \n",
    "                if guessed[idx] == correct[idx]:\n",
    "                    idx += 1\n",
    "                    correctlyFound = True\n",
    "                    \n",
    "                    # Scan until it no longer starts with I\n",
    "                    while idx < len(guessed) and guessed[idx][0] == 'I': \n",
    "                        if guessed[idx] != correct[idx]:\n",
    "                            correctlyFound = False\n",
    "                        \n",
    "                        idx += 1\n",
    "                    \n",
    "                    # The chunk in correct was longer\n",
    "                    if idx < len(guessed):\n",
    "                        if correct[idx][0] == 'I': \n",
    "                            correctlyFound = False\n",
    "                        \n",
    "                    \n",
    "                    if correctlyFound:\n",
    "                        correctCount += 1\n",
    "                else:\n",
    "                    idx += 1\n",
    "            else:  \n",
    "                idx += 1\n",
    "    \n",
    "    precision = 0\n",
    "    if count > 0:    \n",
    "        precision = float(correctCount) / count\n",
    "        \n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_minibatches(dataset): \n",
    "    endIdx = len(dataset)   \n",
    "    for idx in range(endIdx):\n",
    "        tokens, casing, labels = dataset[idx]        \n",
    "            \n",
    "        labels = np.expand_dims([labels], -1)     \n",
    "        yield labels, np.asarray([tokens]), np.asarray([casing])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dataset):\n",
    "    \"\"\"Compute predictions. \n",
    "    Return tuple: predicted labels, correct labels\"\"\"\n",
    "    \n",
    "    correctLabels = []\n",
    "    predLabels = []\n",
    "    for tokens, casing, labels in dataset:    \n",
    "        tokens = np.asarray([tokens])     \n",
    "        casing = np.asarray([casing])\n",
    "        #print('Tokens: ', tokens)\n",
    "        #print('Casing: ', casing)\n",
    "        #print('---')\n",
    "        pred = model.predict([tokens, casing], verbose=False)[0]  \n",
    "        #print(\"Pred1: \", pred)\n",
    "        pred = pred.argmax(axis=-1) #Predict the classes            \n",
    "        #print(\"Pred2: \", pred)\n",
    "        correctLabels.append(labels)\n",
    "        predLabels.append(pred)\n",
    "        \n",
    "        \n",
    "    return predLabels, correctLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(train_data, test_data, number_of_epochs):\n",
    "    \"\"\"Train model and compute precision, recall and F1 score on test data\n",
    "    \"\"\"\n",
    "    for epoch in range(number_of_epochs):    \n",
    "        print(\"--------- Epoch %d -----------\" % epoch)\n",
    "        random.shuffle(train_data)\n",
    "        start_time = time.time()    \n",
    "    \n",
    "        # Train one sentence at a time (i.e. online training) to avoid padding of sentences\n",
    "        cnt = 0\n",
    "        for batch in iterate_minibatches(train_data):\n",
    "            labels, tokens, casing = batch     \n",
    "            # Single gradient update over one batch of samples.   \n",
    "            model.train_on_batch([tokens, casing], labels) \n",
    "            cnt += 1\n",
    "        \n",
    "            if cnt % 100 == 0:\n",
    "                print('Sentence: %d / %d' % (cnt, len(train_data)), end='\\r')\n",
    "        print(\"%.2f sec for training                 \" % (time.time() - start_time))\n",
    "    \n",
    "    \n",
    "    # Performance on test dataset       \n",
    "    predLabels, correctLabels = predict(test_data)        \n",
    "    pre_test, rec_test, f1_test = compute_f1(predLabels, correctLabels, idx2Label)\n",
    "    print(\"Test-Data: Prec: %.3f, Rec: %.3f, F1: %.3f\" % (pre_test, rec_test, f1_test))\n",
    "    \n",
    "    print(\"%.2f sec for evaluation\" % (time.time() - start_time))\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model and compute precision, recall and F1 score on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8228, 3526, 11754, 11755)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_len = len(data)\n",
    "train_pcnt = round(data_len / 100 * 70)\n",
    "test_pcnt = round(data_len / 100 * 30)\n",
    "train_pcnt, test_pcnt, train_pcnt + test_pcnt, data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Fold:  0\n",
      "--------- Epoch 0 -----------\n",
      "166.30 sec for training                 \n",
      "--------- Epoch 1 -----------\n",
      "161.83 sec for training                 \n",
      "--------- Epoch 2 -----------\n",
      "165.99 sec for training                 \n",
      "--------- Epoch 3 -----------\n",
      "162.41 sec for training                 \n",
      "--------- Epoch 4 -----------\n",
      "161.68 sec for training                 \n",
      "--------- Epoch 5 -----------\n",
      "161.58 sec for training                 \n",
      "--------- Epoch 6 -----------\n",
      "161.65 sec for training                 \n",
      "--------- Epoch 7 -----------\n",
      "323.54 sec for training                 \n",
      "--------- Epoch 8 -----------\n",
      "161.75 sec for training                 \n",
      "--------- Epoch 9 -----------\n",
      "161.68 sec for training                 \n",
      "Test-Data: Prec: 0.837, Rec: 0.827, F1: 0.832\n",
      "177.82 sec for evaluation\n",
      "\n",
      "CPU times: user 1h 5min 24s, sys: 12min 47s, total: 1h 18min 11s\n",
      "Wall time: 30min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# k-fold cross  validation\n",
    "folds = 1\n",
    "number_of_epochs = 10\n",
    "for i in range(folds):\n",
    "    print(\"*** Fold: \", i)\n",
    "    random.shuffle(data)\n",
    "    train_data = data[:train_pcnt]\n",
    "    test_data = data[train_pcnt:]\n",
    "    train_test(train_data, test_data, number_of_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model in a HDF5 file \n",
    "model.save(MODEL_PATH)  "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
