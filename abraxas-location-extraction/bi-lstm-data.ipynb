{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import gzip\n",
    "import sys\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1337)  # for reproducibility\n",
    "DATA_PATH = \"bi-lstm-data/\"\n",
    "EMBEDDINGS_PATH = DATA_PATH+'embeddings.pkl.gz'\n",
    "TRAIN_SET_PATH = DATA_PATH+'train_set.pkl.gz'\n",
    "TEST_SET_PATH = DATA_PATH+'test_set.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "Read NLTK Spanish corpus.\n",
    "\n",
    "https://github.com/teropa/nlp/tree/master/resources/corpora/conll2002"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "These files contain the train and test data for for the three parts of \n",
    "the CoNLL-2002 shared task:\n",
    "\n",
    "   esp.testa: Spanish test data for the development stage\n",
    "   esp.testb: Spanish test data\n",
    "   esp.train: Spanish train data\n",
    "   ned.testa: Dutch test data for the development stage\n",
    "   ned.testb: Dutch test data\n",
    "   ned.train: Dutch train data\n",
    "\n",
    "All data files contain a single word per line with it associated \n",
    "named entity tag in the IOB2 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package conll2002 to /Users/dk/nltk_data...\n",
      "[nltk_data]   Package conll2002 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['esp.testa', 'esp.testb', 'esp.train', 'ned.testa', 'ned.testb', 'ned.train']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('conll2002')\n",
    "nltk.corpus.conll2002.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.77 s, sys: 131 ms, total: 2.9 s\n",
      "Wall time: 2.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_sents = list(nltk.corpus.conll2002.iob_sents('esp.train'))\n",
    "test_sents = list(nltk.corpus.conll2002.iob_sents('esp.testb'))\n",
    "dev_sents = list(nltk.corpus.conll2002.iob_sents('esp.testa'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11755"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = train_sents + test_sents + dev_sents\n",
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Por', 'SP', 'O'),\n",
       " ('su', 'DP', 'O'),\n",
       " ('parte', 'NC', 'O'),\n",
       " (',', 'Fc', 'O'),\n",
       " ('el', 'DA', 'O'),\n",
       " ('Abogado', 'NC', 'B-PER'),\n",
       " ('General', 'AQ', 'I-PER'),\n",
       " ('de', 'SP', 'O'),\n",
       " ('Victoria', 'NC', 'B-LOC'),\n",
       " (',', 'Fc', 'O'),\n",
       " ('Rob', 'NC', 'B-PER'),\n",
       " ('Hulls', 'AQ', 'I-PER'),\n",
       " (',', 'Fc', 'O'),\n",
       " ('indicó', 'VMI', 'O'),\n",
       " ('que', 'CS', 'O'),\n",
       " ('no', 'RN', 'O'),\n",
       " ('hay', 'VAI', 'O'),\n",
       " ('nadie', 'PI', 'O'),\n",
       " ('que', 'PR', 'O'),\n",
       " ('controle', 'VMS', 'O'),\n",
       " ('que', 'CS', 'O'),\n",
       " ('las', 'DA', 'O'),\n",
       " ('informaciones', 'NC', 'O'),\n",
       " ('contenidas', 'AQ', 'O'),\n",
       " ('en', 'SP', 'O'),\n",
       " ('CrimeNet', 'NC', 'B-MISC'),\n",
       " ('son', 'VSI', 'O'),\n",
       " ('veraces', 'AQ', 'O'),\n",
       " ('.', 'Fp', 'O')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sentences(sentences):\n",
    "    ''' Read sentences. For each sentence there is one token per line, \n",
    "    each with its part-of-speech tag and its named entity tag.\n",
    "    Remove POS tag and leave only NE tag'''\n",
    "    \n",
    "    sentence_list = []\n",
    "    for sentence in sentences:\n",
    "        sentence_words = []\n",
    "        for word in sentence:\n",
    "            word_list = [word[0], word[2]]\n",
    "            sentence_words.append(word_list)\n",
    "        sentence_list.append(sentence_words)\n",
    "    print(len(sentence_list), 'sentences')\n",
    "    return(sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11755 sentences\n"
     ]
    }
   ],
   "source": [
    "data = read_sentences(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Por', 'O'],\n",
       " ['su', 'O'],\n",
       " ['parte', 'O'],\n",
       " [',', 'O'],\n",
       " ['el', 'O'],\n",
       " ['Abogado', 'B-PER'],\n",
       " ['General', 'I-PER'],\n",
       " ['de', 'O'],\n",
       " ['Victoria', 'B-LOC'],\n",
       " [',', 'O'],\n",
       " ['Rob', 'B-PER'],\n",
       " ['Hulls', 'I-PER'],\n",
       " [',', 'O'],\n",
       " ['indicó', 'O'],\n",
       " ['que', 'O'],\n",
       " ['no', 'O'],\n",
       " ['hay', 'O'],\n",
       " ['nadie', 'O'],\n",
       " ['que', 'O'],\n",
       " ['controle', 'O'],\n",
       " ['que', 'O'],\n",
       " ['las', 'O'],\n",
       " ['informaciones', 'O'],\n",
       " ['contenidas', 'O'],\n",
       " ['en', 'O'],\n",
       " ['CrimeNet', 'B-MISC'],\n",
       " ['son', 'O'],\n",
       " ['veraces', 'O'],\n",
       " ['.', 'O']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Location counts B-LOC:  6981  I-LOC:  2553\n"
     ]
    }
   ],
   "source": [
    "# Count location words\n",
    "b_cnt = 0\n",
    "i_cnt = 0\n",
    "loc = set()\n",
    "for lst in data:\n",
    "    for x in lst:\n",
    "        if x[1] == 'B-LOC':\n",
    "            loc.add(str(x))\n",
    "            b_cnt += 1\n",
    "        elif x[1] == 'I-LOC':\n",
    "            loc.add(str(x))\n",
    "            i_cnt += 1\n",
    "            #print(x[0])    \n",
    "print(\"**** Location counts B-LOC: \", b_cnt, \" I-LOC: \", i_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create case embeddings with hard coded case lookup\n",
    "case2Idx = {'numeric': 0, 'allLower':1, 'allUpper':2, 'initialUpper':3, 'other':4, 'mainly_numeric':5, 'contains_digit': 6, 'PADDING_TOKEN':7}\n",
    "caseEmbeddings = np.identity(len(case2Idx), dtype='float32')\n",
    "len(case2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caseEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCasing(word, caseLookup):   \n",
    "    casing = 'other'\n",
    "    \n",
    "    numDigits = 0\n",
    "    for char in word:\n",
    "        if char.isdigit():\n",
    "            numDigits += 1\n",
    "            \n",
    "    digitFraction = numDigits / float(len(word))\n",
    "    \n",
    "    if word.isdigit(): #Is a digit\n",
    "        casing = 'numeric'\n",
    "    elif digitFraction > 0.5:\n",
    "        casing = 'mainly_numeric'\n",
    "    elif word.islower(): #All lower case\n",
    "        casing = 'allLower'\n",
    "    elif word.isupper(): #All upper case\n",
    "        casing = 'allUpper'\n",
    "    elif word[0].isupper(): #is a title, initial char upper, then all lower\n",
    "        casing = 'initialUpper'\n",
    "    elif numDigits > 0:\n",
    "        casing = 'contains_digit'\n",
    "      \n",
    "    return caseLookup[casing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect words and labels from conll2002\n",
    "labelSet = set() \n",
    "words = {}\n",
    "for sentence in data:\n",
    "    for token, label in sentence:\n",
    "        labelSet.add(label)\n",
    "        words[token.lower()] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2419 entries, 0 to 2418\n",
      "Data columns (total 10 columns):\n",
      "Folio         2419 non-null int64\n",
      "Fecha         2419 non-null object\n",
      "Nivel_1       2419 non-null object\n",
      "Nivel_2       2419 non-null object\n",
      "Nivel_3       2416 non-null object\n",
      "Titulo        2419 non-null object\n",
      "Sintesis      2255 non-null object\n",
      "Texto         2415 non-null object\n",
      "Unnamed: 8    198 non-null object\n",
      "Unnamed: 9    5 non-null object\n",
      "dtypes: int64(1), object(9)\n",
      "memory usage: 189.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Folio</th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Nivel_1</th>\n",
       "      <th>Nivel_2</th>\n",
       "      <th>Nivel_3</th>\n",
       "      <th>Titulo</th>\n",
       "      <th>Sintesis</th>\n",
       "      <th>Texto</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>08/20/2017</td>\n",
       "      <td>ActivismoSocial</td>\n",
       "      <td>Marcha</td>\n",
       "      <td>Sindicato</td>\n",
       "      <td>Exigen a TransCanada transparentar proyecto de...</td>\n",
       "      <td>Presidentes de las sociedades cooperativas pes...</td>\n",
       "      <td>Presidentes de las sociedades cooperativas pes...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>08/18/2017</td>\n",
       "      <td>ActivismoSocial</td>\n",
       "      <td>Marcha</td>\n",
       "      <td>Sindicato</td>\n",
       "      <td>iVan a cerrar la carretera Tuxpan-Tamiahua!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tamaulipas, Ver.- Por los danos que ocasionan ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>08/18/2017</td>\n",
       "      <td>ActivismoSocial</td>\n",
       "      <td>Marcha</td>\n",
       "      <td>Sindicato</td>\n",
       "      <td>iVan a cerrar la carretera Tuxpan-Tamiahua!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tamaulipas, Ver.- Por los danos que ocasionan ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Folio       Fecha          Nivel_1 Nivel_2    Nivel_3  \\\n",
       "0      1  08/20/2017  ActivismoSocial  Marcha  Sindicato   \n",
       "1      2  08/18/2017  ActivismoSocial  Marcha  Sindicato   \n",
       "2      3  08/18/2017  ActivismoSocial  Marcha  Sindicato   \n",
       "\n",
       "                                              Titulo  \\\n",
       "0  Exigen a TransCanada transparentar proyecto de...   \n",
       "1    iVan a cerrar la carretera Tuxpan-Tamiahua!       \n",
       "2    iVan a cerrar la carretera Tuxpan-Tamiahua!       \n",
       "\n",
       "                                            Sintesis  \\\n",
       "0  Presidentes de las sociedades cooperativas pes...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "\n",
       "                                               Texto Unnamed: 8 Unnamed: 9  \n",
       "0  Presidentes de las sociedades cooperativas pes...        NaN        NaN  \n",
       "1  Tamaulipas, Ver.- Por los danos que ocasionan ...        NaN        NaN  \n",
       "2  Tamaulipas, Ver.- Por los danos que ocasionan ...        NaN        NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read events\n",
    "inputFilePath = \"./data/Corpus.csv\"\n",
    "df_raw = pd.read_csv(inputFilePath)#, sep=';')\n",
    "df_raw.info()\n",
    "df_raw.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2251 entries, 0 to 2250\n",
      "Data columns (total 3 columns):\n",
      "Titulo      2251 non-null object\n",
      "Sintesis    2251 non-null object\n",
      "Texto       2251 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 52.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titulo</th>\n",
       "      <th>Sintesis</th>\n",
       "      <th>Texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Exigen a TransCanada transparentar proyecto de...</td>\n",
       "      <td>Presidentes de las sociedades cooperativas pes...</td>\n",
       "      <td>Presidentes de las sociedades cooperativas pes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Violento fin de semana en dos estados de Mexic...</td>\n",
       "      <td>Los casos ocurrieron en Guanajuato y Chihuahua...</td>\n",
       "      <td>Los casos ocurrieron en Guanajuato y Chihuahua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Expulsan a 3 personas en Pahuatlan por trabaja...</td>\n",
       "      <td>Los empleados de la TransCanada regresaban de ...</td>\n",
       "      <td>Los empleados de la TransCanada regresaban de ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Titulo  \\\n",
       "0  Exigen a TransCanada transparentar proyecto de...   \n",
       "1  Violento fin de semana en dos estados de Mexic...   \n",
       "2  Expulsan a 3 personas en Pahuatlan por trabaja...   \n",
       "\n",
       "                                            Sintesis  \\\n",
       "0  Presidentes de las sociedades cooperativas pes...   \n",
       "1  Los casos ocurrieron en Guanajuato y Chihuahua...   \n",
       "2  Los empleados de la TransCanada regresaban de ...   \n",
       "\n",
       "                                               Texto  \n",
       "0  Presidentes de las sociedades cooperativas pes...  \n",
       "1  Los casos ocurrieron en Guanajuato y Chihuahua...  \n",
       "2  Los empleados de la TransCanada regresaban de ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select news \n",
    "df = pd.DataFrame() \n",
    "df = df_raw[['Titulo', 'Sintesis', 'Texto']]#.copy()\n",
    "df = df.dropna()\n",
    "df = df.reset_index()\n",
    "df = df.drop(['index'], axis = 1)\n",
    "df.info()\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cuatro personas fueron ejecutadas esta noche en la Ciudad de Chihuahua, informaron autoridades.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sintesis'][8]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"Four people were executed tonight in the City of Chihuahua, authorities said.\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Tokenize events\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textTokens(text, words_dict) :\n",
    "    \"\"\"Split text into a list of tokens. Add toknes to the external 'words' dictionary. \n",
    "    Return a list of tokens.\n",
    "    \"\"\"\n",
    "    text_tokens = []    \n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        sent_tokens = []\n",
    "        for token in nltk.word_tokenize(sent):\n",
    "            #print(token)\n",
    "            sent_tokens.append(token)          \n",
    "            words_dict[token.lower()] = True\n",
    "        text_tokens.append(sent_tokens)\n",
    "    return (text_tokens)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28382"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29986"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add words from 'Titulo' column to words dictionary\n",
    "df['titulo_tokens'] = df['Titulo'].apply(lambda text: textTokens(text, words))\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33187"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add words from 'Sintesis' column to words dictionary\n",
    "df['sintesis_tokens'] = df['Sintesis'].apply(lambda text: textTokens(text, words))\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43221"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add words from 'Texto' column to words dictionary\n",
    "df['texto_tokens'] = df['Texto'].apply(lambda text: textTokens(text, words))\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titulo</th>\n",
       "      <th>Sintesis</th>\n",
       "      <th>Texto</th>\n",
       "      <th>titulo_tokens</th>\n",
       "      <th>sintesis_tokens</th>\n",
       "      <th>texto_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Exigen a TransCanada transparentar proyecto de...</td>\n",
       "      <td>Presidentes de las sociedades cooperativas pes...</td>\n",
       "      <td>Presidentes de las sociedades cooperativas pes...</td>\n",
       "      <td>[[Exigen, a, TransCanada, transparentar, proye...</td>\n",
       "      <td>[[Presidentes, de, las, sociedades, cooperativ...</td>\n",
       "      <td>[[Presidentes, de, las, sociedades, cooperativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Violento fin de semana en dos estados de Mexic...</td>\n",
       "      <td>Los casos ocurrieron en Guanajuato y Chihuahua...</td>\n",
       "      <td>Los casos ocurrieron en Guanajuato y Chihuahua...</td>\n",
       "      <td>[[Violento, fin, de, semana, en, dos, estados,...</td>\n",
       "      <td>[[Los, casos, ocurrieron, en, Guanajuato, y, C...</td>\n",
       "      <td>[[Los, casos, ocurrieron, en, Guanajuato, y, C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Expulsan a 3 personas en Pahuatlan por trabaja...</td>\n",
       "      <td>Los empleados de la TransCanada regresaban de ...</td>\n",
       "      <td>Los empleados de la TransCanada regresaban de ...</td>\n",
       "      <td>[[Expulsan, a, 3, personas, en, Pahuatlan, por...</td>\n",
       "      <td>[[Los, empleados, de, la, TransCanada, regresa...</td>\n",
       "      <td>[[Los, empleados, de, la, TransCanada, regresa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Enfrentamiento entre civiles y militares deja ...</td>\n",
       "      <td>Los hechos se registraron la madrugada de este...</td>\n",
       "      <td>se reporta una persona detenida.</td>\n",
       "      <td>[[Enfrentamiento, entre, civiles, y, militares...</td>\n",
       "      <td>[[Los, hechos, se, registraron, la, madrugada,...</td>\n",
       "      <td>[[se, reporta, una, persona, detenida, .]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Identifican a joven localizada sin vida en Gua...</td>\n",
       "      <td>La joven madre fue identificada como Rosario J...</td>\n",
       "      <td>La joven madre fue identificada como Rosario J...</td>\n",
       "      <td>[[Identifican, a, joven, localizada, sin, vida...</td>\n",
       "      <td>[[La, joven, madre, fue, identificada, como, R...</td>\n",
       "      <td>[[La, joven, madre, fue, identificada, como, R...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Titulo  \\\n",
       "0  Exigen a TransCanada transparentar proyecto de...   \n",
       "1  Violento fin de semana en dos estados de Mexic...   \n",
       "2  Expulsan a 3 personas en Pahuatlan por trabaja...   \n",
       "3  Enfrentamiento entre civiles y militares deja ...   \n",
       "4  Identifican a joven localizada sin vida en Gua...   \n",
       "\n",
       "                                            Sintesis  \\\n",
       "0  Presidentes de las sociedades cooperativas pes...   \n",
       "1  Los casos ocurrieron en Guanajuato y Chihuahua...   \n",
       "2  Los empleados de la TransCanada regresaban de ...   \n",
       "3  Los hechos se registraron la madrugada de este...   \n",
       "4  La joven madre fue identificada como Rosario J...   \n",
       "\n",
       "                                               Texto  \\\n",
       "0  Presidentes de las sociedades cooperativas pes...   \n",
       "1  Los casos ocurrieron en Guanajuato y Chihuahua...   \n",
       "2  Los empleados de la TransCanada regresaban de ...   \n",
       "3                  se reporta una persona detenida.    \n",
       "4  La joven madre fue identificada como Rosario J...   \n",
       "\n",
       "                                       titulo_tokens  \\\n",
       "0  [[Exigen, a, TransCanada, transparentar, proye...   \n",
       "1  [[Violento, fin, de, semana, en, dos, estados,...   \n",
       "2  [[Expulsan, a, 3, personas, en, Pahuatlan, por...   \n",
       "3  [[Enfrentamiento, entre, civiles, y, militares...   \n",
       "4  [[Identifican, a, joven, localizada, sin, vida...   \n",
       "\n",
       "                                     sintesis_tokens  \\\n",
       "0  [[Presidentes, de, las, sociedades, cooperativ...   \n",
       "1  [[Los, casos, ocurrieron, en, Guanajuato, y, C...   \n",
       "2  [[Los, empleados, de, la, TransCanada, regresa...   \n",
       "3  [[Los, hechos, se, registraron, la, madrugada,...   \n",
       "4  [[La, joven, madre, fue, identificada, como, R...   \n",
       "\n",
       "                                        texto_tokens  \n",
       "0  [[Presidentes, de, las, sociedades, cooperativ...  \n",
       "1  [[Los, casos, ocurrieron, en, Guanajuato, y, C...  \n",
       "2  [[Los, empleados, de, la, TransCanada, regresa...  \n",
       "3         [[se, reporta, una, persona, detenida, .]]  \n",
       "4  [[La, joven, madre, fue, identificada, como, R...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping for the labels \n",
    "label2Idx = {}\n",
    "for label in labelSet:\n",
    "    label2Idx[label] = len(label2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-MISC': 0,\n",
       " 'B-LOC': 1,\n",
       " 'I-PER': 2,\n",
       " 'I-ORG': 3,\n",
       " 'O': 4,\n",
       " 'I-MISC': 5,\n",
       " 'B-PER': 6,\n",
       " 'I-LOC': 7,\n",
       " 'B-ORG': 8}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2Idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word embeddings\n",
    "Read in embeddings from 'Spanish Billion Words Corpus and Embeddings linguistic resource'.\n",
    "https://crscardellino.github.io/SBWCE/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'1000653 300\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2Idx = {}\n",
    "wordEmbeddings = []\n",
    "embeddingsPath = \"./word2vec-spanish-vectors/SBW-vectors-300-min5.txt.gz\"\n",
    "# Load the pre-trained embeddings file \n",
    "fEmbeddings = gzip.open(\n",
    "    embeddingsPath, \"r\") if embeddingsPath.endswith('.gz') else open(\n",
    "    embeddingsPath, encoding=\"utf8\")\n",
    "\n",
    "fEmbeddings.readline() #skip first line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45.6 s, sys: 391 ms, total: 46 s\n",
      "Wall time: 46.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Find embedding vectors that match words from our corpus and events\n",
    "for line in fEmbeddings:\n",
    "    split = line.decode(\"utf-8\").strip().split(\" \")\n",
    "    word = split[0]\n",
    "    \n",
    "    if len(word2Idx) == 0: #Add padding+unknown\n",
    "        word2Idx[\"PADDING_TOKEN\"] = len(word2Idx)\n",
    "        vector = np.zeros(len(split)-1) #Zero vector vor 'PADDING' word\n",
    "        wordEmbeddings.append(vector)\n",
    "        \n",
    "        word2Idx[\"UNKNOWN_TOKEN\"] = len(word2Idx)\n",
    "        vector = np.random.uniform(-0.25, 0.25, len(split)-1)\n",
    "        wordEmbeddings.append(vector)\n",
    "\n",
    "    if split[0].lower() in words:\n",
    "        vector = np.array([float(num) for num in split[1:]])\n",
    "        wordEmbeddings.append(vector)\n",
    "        word2Idx[split[0]] = len(word2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape:  (75272, 300)\n"
     ]
    }
   ],
   "source": [
    "wordEmbeddings = np.array(wordEmbeddings)\n",
    "print(\"Embeddings shape: \", wordEmbeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store embeddings\n",
    "embeddings = {'wordEmbeddings': wordEmbeddings, 'word2Idx': word2Idx,\n",
    "              'caseEmbeddings': caseEmbeddings, 'case2Idx': case2Idx,\n",
    "              'label2Idx': label2Idx}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-MISC': 0, 'B-LOC': 1, 'I-PER': 2, 'I-ORG': 3, 'O': 4, 'I-MISC': 5, 'B-PER': 6, 'I-LOC': 7, 'B-ORG': 8} \n",
      "---\n",
      " {'numeric': 0, 'allLower': 1, 'allUpper': 2, 'initialUpper': 3, 'other': 4, 'mainly_numeric': 5, 'contains_digit': 6, 'PADDING_TOKEN': 7}\n"
     ]
    }
   ],
   "source": [
    "print(label2Idx, '\\n---\\n',case2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save embeddings\n",
    "f = gzip.open(EMBEDDINGS_PATH, 'wb')\n",
    "pkl.dump(embeddings, f, -1)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train set matrices\n",
    "def createMatrices(sentences, word2Idx, label2Idx, case2Idx):\n",
    "    unknownIdx = word2Idx['UNKNOWN_TOKEN']\n",
    "    #paddingIdx = word2Idx['PADDING_TOKEN']    \n",
    "        \n",
    "    dataset = []\n",
    "    \n",
    "    wordCount = 0\n",
    "    unknownWordCount = 0\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        wordIndices = []    \n",
    "        caseIndices = []\n",
    "        labelIndices = []\n",
    "        \n",
    "        for word, label in sentence:  \n",
    "            wordCount += 1\n",
    "            if word in word2Idx:\n",
    "                wordIdx = word2Idx[word]\n",
    "            elif word.lower() in word2Idx:\n",
    "                wordIdx = word2Idx[word.lower()]                 \n",
    "            else:\n",
    "                wordIdx = unknownIdx\n",
    "                unknownWordCount += 1\n",
    "            \n",
    "            #Get the label and map to int            \n",
    "            wordIndices.append(wordIdx)\n",
    "            caseIndices.append(getCasing(word, case2Idx))\n",
    "            labelIndices.append(label2Idx[label])\n",
    "           \n",
    "        dataset.append([wordIndices, caseIndices, labelIndices]) \n",
    "        \n",
    "        \n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = createMatrices(data, word2Idx,  label2Idx, case2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[12558, 1, 1445, 1, 1, 1, 18468, 1, 6566, 1, 1],\n",
       " [3, 4, 3, 4, 4, 0, 1, 4, 2, 4, 4],\n",
       " [1, 4, 1, 4, 4, 4, 4, 4, 8, 4, 4]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11755"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save train set\n",
    "f = gzip.open(TRAIN_SET_PATH, 'wb')\n",
    "pkl.dump(train_set, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTestMatrices(text, word2Idx, case2Idx):\n",
    "    unknownIdx = word2Idx['UNKNOWN_TOKEN']\n",
    "    paddingIdx = word2Idx['PADDING_TOKEN']    \n",
    "        \n",
    "    dataset = []  \n",
    "    wordCount = 0\n",
    "    unknownWordCount = 0\n",
    "    text_wordIndices = []    \n",
    "    text_caseIndices = []\n",
    "    \n",
    "    for sentence in text:\n",
    "        sent_wordIndices = []    \n",
    "        sent_caseIndices = []\n",
    "        for word in sentence:  \n",
    "            wordCount += 1\n",
    "            if word in word2Idx:\n",
    "                wordIdx = word2Idx[word]\n",
    "            elif word.lower() in word2Idx:\n",
    "                wordIdx = word2Idx[word.lower()]                 \n",
    "            else:\n",
    "                wordIdx = unknownIdx\n",
    "                unknownWordCount += 1\n",
    "                        \n",
    "            sent_wordIndices.append(wordIdx)\n",
    "            sent_caseIndices.append(getCasing(word, case2Idx))        \n",
    "        \n",
    "        text_wordIndices.append(sent_wordIndices)\n",
    "        text_caseIndices.append(sent_caseIndices)\n",
    "        \n",
    "    return (text_wordIndices, text_caseIndices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add word and case indexes to dataframe\n",
    "df[['titulo_word_inds','titulo_case_inds']] = df.apply(lambda x: pd.Series(createTestMatrices(x['titulo_tokens'], word2Idx, case2Idx)), axis=1)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['sintesis_word_inds','sintesis_case_inds']] = df.apply(lambda x: pd.Series(createTestMatrices(x['sintesis_tokens'], word2Idx, case2Idx)), axis=1)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titulo</th>\n",
       "      <th>Sintesis</th>\n",
       "      <th>Texto</th>\n",
       "      <th>titulo_tokens</th>\n",
       "      <th>sintesis_tokens</th>\n",
       "      <th>texto_tokens</th>\n",
       "      <th>titulo_word_inds</th>\n",
       "      <th>titulo_case_inds</th>\n",
       "      <th>sintesis_word_inds</th>\n",
       "      <th>sintesis_case_inds</th>\n",
       "      <th>texto_word_inds</th>\n",
       "      <th>texto_case_inds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Exigen a TransCanada transparentar proyecto de...</td>\n",
       "      <td>Presidentes de las sociedades cooperativas pes...</td>\n",
       "      <td>Presidentes de las sociedades cooperativas pes...</td>\n",
       "      <td>[[Exigen, a, TransCanada, transparentar, proye...</td>\n",
       "      <td>[[Presidentes, de, las, sociedades, cooperativ...</td>\n",
       "      <td>[[Presidentes, de, las, sociedades, cooperativ...</td>\n",
       "      <td>[[23151, 8, 56126, 25835, 128, 2, 20125]]</td>\n",
       "      <td>[[3, 1, 3, 1, 1, 1, 1]]</td>\n",
       "      <td>[[8276, 2, 11, 2597, 8975, 13703, 2, 47087, 6,...</td>\n",
       "      <td>[[3, 1, 1, 1, 1, 1, 1, 3, 1, 3, 4, 1, 1, 1, 3,...</td>\n",
       "      <td>[[8276, 2, 11, 2597, 8975, 13703, 2, 47087, 6,...</td>\n",
       "      <td>[[3, 1, 1, 1, 1, 1, 1, 3, 1, 3, 4, 1, 1, 1, 3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Violento fin de semana en dos estados de Mexic...</td>\n",
       "      <td>Los casos ocurrieron en Guanajuato y Chihuahua...</td>\n",
       "      <td>Los casos ocurrieron en Guanajuato y Chihuahua...</td>\n",
       "      <td>[[Violento, fin, de, semana, en, dos, estados,...</td>\n",
       "      <td>[[Los, casos, ocurrieron, en, Guanajuato, y, C...</td>\n",
       "      <td>[[Los, casos, ocurrieron, en, Guanajuato, y, C...</td>\n",
       "      <td>[[42177, 127, 2, 435, 4, 38, 1425, 2, 16336, 1...</td>\n",
       "      <td>[[3, 1, 1, 1, 1, 1, 1, 1, 3, 4, 0, 1]]</td>\n",
       "      <td>[[35, 301, 8038, 4, 5840, 6, 6319, 1], [5285, ...</td>\n",
       "      <td>[[3, 1, 1, 1, 3, 1, 3, 4], [3, 1, 5, 1, 1, 1, ...</td>\n",
       "      <td>[[35, 301, 8038, 4, 5840, 6, 6319, 1], [5285, ...</td>\n",
       "      <td>[[3, 1, 1, 1, 3, 1, 3, 4], [3, 1, 5, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Expulsan a 3 personas en Pahuatlan por trabaja...</td>\n",
       "      <td>Los empleados de la TransCanada regresaban de ...</td>\n",
       "      <td>Los empleados de la TransCanada regresaban de ...</td>\n",
       "      <td>[[Expulsan, a, 3, personas, en, Pahuatlan, por...</td>\n",
       "      <td>[[Los, empleados, de, la, TransCanada, regresa...</td>\n",
       "      <td>[[Los, empleados, de, la, TransCanada, regresa...</td>\n",
       "      <td>[[48750, 8, 1, 71, 4, 66437, 13, 926, 4, 20125]]</td>\n",
       "      <td>[[3, 1, 0, 1, 1, 3, 1, 1, 1, 1]]</td>\n",
       "      <td>[[35, 1659, 2, 3, 56126, 21451, 2, 855, 103, 2...</td>\n",
       "      <td>[[3, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "      <td>[[35, 1659, 2, 3, 56126, 21451, 2, 855, 103, 2...</td>\n",
       "      <td>[[3, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Enfrentamiento entre civiles y militares deja ...</td>\n",
       "      <td>Los hechos se registraron la madrugada de este...</td>\n",
       "      <td>se reporta una persona detenida.</td>\n",
       "      <td>[[Enfrentamiento, entre, civiles, y, militares...</td>\n",
       "      <td>[[Los, hechos, se, registraron, la, madrugada,...</td>\n",
       "      <td>[[se, reporta, una, persona, detenida, .]]</td>\n",
       "      <td>[[32119, 33, 1148, 6, 872, 1877, 1, 1752, 4, 6...</td>\n",
       "      <td>[[3, 1, 1, 1, 1, 1, 0, 1, 1, 3]]</td>\n",
       "      <td>[[35, 834, 12, 4628, 3, 3223, 2, 34, 1199, 4, ...</td>\n",
       "      <td>[[3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]]</td>\n",
       "      <td>[[12, 12611, 17, 429, 8479, 1]]</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 4]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Identifican a joven localizada sin vida en Gua...</td>\n",
       "      <td>La joven madre fue identificada como Rosario J...</td>\n",
       "      <td>La joven madre fue identificada como Rosario J...</td>\n",
       "      <td>[[Identifican, a, joven, localizada, sin, vida...</td>\n",
       "      <td>[[La, joven, madre, fue, identificada, como, R...</td>\n",
       "      <td>[[La, joven, madre, fue, identificada, como, R...</td>\n",
       "      <td>[[29293, 8, 779, 7394, 54, 133, 4, 57330]]</td>\n",
       "      <td>[[3, 1, 1, 1, 1, 1, 1, 3]]</td>\n",
       "      <td>[[24, 779, 842, 32, 9692, 23, 3764, 17412, 1, ...</td>\n",
       "      <td>[[3, 1, 1, 1, 1, 1, 3, 3, 2, 2, 4, 1, 1, 3, 4,...</td>\n",
       "      <td>[[24, 779, 842, 32, 9692, 23, 3764, 17412, 1, ...</td>\n",
       "      <td>[[3, 1, 1, 1, 1, 1, 3, 3, 2, 2, 4, 1, 1, 3, 4,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Titulo  \\\n",
       "0  Exigen a TransCanada transparentar proyecto de...   \n",
       "1  Violento fin de semana en dos estados de Mexic...   \n",
       "2  Expulsan a 3 personas en Pahuatlan por trabaja...   \n",
       "3  Enfrentamiento entre civiles y militares deja ...   \n",
       "4  Identifican a joven localizada sin vida en Gua...   \n",
       "\n",
       "                                            Sintesis  \\\n",
       "0  Presidentes de las sociedades cooperativas pes...   \n",
       "1  Los casos ocurrieron en Guanajuato y Chihuahua...   \n",
       "2  Los empleados de la TransCanada regresaban de ...   \n",
       "3  Los hechos se registraron la madrugada de este...   \n",
       "4  La joven madre fue identificada como Rosario J...   \n",
       "\n",
       "                                               Texto  \\\n",
       "0  Presidentes de las sociedades cooperativas pes...   \n",
       "1  Los casos ocurrieron en Guanajuato y Chihuahua...   \n",
       "2  Los empleados de la TransCanada regresaban de ...   \n",
       "3                  se reporta una persona detenida.    \n",
       "4  La joven madre fue identificada como Rosario J...   \n",
       "\n",
       "                                       titulo_tokens  \\\n",
       "0  [[Exigen, a, TransCanada, transparentar, proye...   \n",
       "1  [[Violento, fin, de, semana, en, dos, estados,...   \n",
       "2  [[Expulsan, a, 3, personas, en, Pahuatlan, por...   \n",
       "3  [[Enfrentamiento, entre, civiles, y, militares...   \n",
       "4  [[Identifican, a, joven, localizada, sin, vida...   \n",
       "\n",
       "                                     sintesis_tokens  \\\n",
       "0  [[Presidentes, de, las, sociedades, cooperativ...   \n",
       "1  [[Los, casos, ocurrieron, en, Guanajuato, y, C...   \n",
       "2  [[Los, empleados, de, la, TransCanada, regresa...   \n",
       "3  [[Los, hechos, se, registraron, la, madrugada,...   \n",
       "4  [[La, joven, madre, fue, identificada, como, R...   \n",
       "\n",
       "                                        texto_tokens  \\\n",
       "0  [[Presidentes, de, las, sociedades, cooperativ...   \n",
       "1  [[Los, casos, ocurrieron, en, Guanajuato, y, C...   \n",
       "2  [[Los, empleados, de, la, TransCanada, regresa...   \n",
       "3         [[se, reporta, una, persona, detenida, .]]   \n",
       "4  [[La, joven, madre, fue, identificada, como, R...   \n",
       "\n",
       "                                    titulo_word_inds  \\\n",
       "0          [[23151, 8, 56126, 25835, 128, 2, 20125]]   \n",
       "1  [[42177, 127, 2, 435, 4, 38, 1425, 2, 16336, 1...   \n",
       "2   [[48750, 8, 1, 71, 4, 66437, 13, 926, 4, 20125]]   \n",
       "3  [[32119, 33, 1148, 6, 872, 1877, 1, 1752, 4, 6...   \n",
       "4         [[29293, 8, 779, 7394, 54, 133, 4, 57330]]   \n",
       "\n",
       "                         titulo_case_inds  \\\n",
       "0                 [[3, 1, 3, 1, 1, 1, 1]]   \n",
       "1  [[3, 1, 1, 1, 1, 1, 1, 1, 3, 4, 0, 1]]   \n",
       "2        [[3, 1, 0, 1, 1, 3, 1, 1, 1, 1]]   \n",
       "3        [[3, 1, 1, 1, 1, 1, 0, 1, 1, 3]]   \n",
       "4              [[3, 1, 1, 1, 1, 1, 1, 3]]   \n",
       "\n",
       "                                  sintesis_word_inds  \\\n",
       "0  [[8276, 2, 11, 2597, 8975, 13703, 2, 47087, 6,...   \n",
       "1  [[35, 301, 8038, 4, 5840, 6, 6319, 1], [5285, ...   \n",
       "2  [[35, 1659, 2, 3, 56126, 21451, 2, 855, 103, 2...   \n",
       "3  [[35, 834, 12, 4628, 3, 3223, 2, 34, 1199, 4, ...   \n",
       "4  [[24, 779, 842, 32, 9692, 23, 3764, 17412, 1, ...   \n",
       "\n",
       "                                  sintesis_case_inds  \\\n",
       "0  [[3, 1, 1, 1, 1, 1, 1, 3, 1, 3, 4, 1, 1, 1, 3,...   \n",
       "1  [[3, 1, 1, 1, 3, 1, 3, 4], [3, 1, 5, 1, 1, 1, ...   \n",
       "2  [[3, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n",
       "3       [[3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]]   \n",
       "4  [[3, 1, 1, 1, 1, 1, 3, 3, 2, 2, 4, 1, 1, 3, 4,...   \n",
       "\n",
       "                                     texto_word_inds  \\\n",
       "0  [[8276, 2, 11, 2597, 8975, 13703, 2, 47087, 6,...   \n",
       "1  [[35, 301, 8038, 4, 5840, 6, 6319, 1], [5285, ...   \n",
       "2  [[35, 1659, 2, 3, 56126, 21451, 2, 855, 103, 2...   \n",
       "3                    [[12, 12611, 17, 429, 8479, 1]]   \n",
       "4  [[24, 779, 842, 32, 9692, 23, 3764, 17412, 1, ...   \n",
       "\n",
       "                                     texto_case_inds  \n",
       "0  [[3, 1, 1, 1, 1, 1, 1, 3, 1, 3, 4, 1, 1, 1, 3,...  \n",
       "1  [[3, 1, 1, 1, 3, 1, 3, 4], [3, 1, 5, 1, 1, 1, ...  \n",
       "2  [[3, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...  \n",
       "3                               [[1, 1, 1, 1, 1, 4]]  \n",
       "4  [[3, 1, 1, 1, 1, 1, 3, 3, 2, 2, 4, 1, 1, 3, 4,...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['texto_word_inds','texto_case_inds']] = df.apply(lambda x: pd.Series(createTestMatrices(x['texto_tokens'], word2Idx, case2Idx)), axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save test set\n",
    "df.to_csv(TEST_SET_PATH, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
