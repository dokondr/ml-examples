{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "print(keras.__version__)\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN layer params\n",
    "VOCAB_SIZE = 10000\n",
    "EMBEDDING_DIMS = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 25000 entries, 0 to 24999\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   SentimentText  25000 non-null  object\n",
      " 1   Sentiment      25000 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 585.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentimentText</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>first think another disney movie might good it...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>put aside dr house repeat missed desperate hou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>big fan stephen king s work film made even gre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>watched horrid thing tv needless say one movie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>truly enjoyed film acting terrific plot jeff c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       SentimentText  Sentiment\n",
       "0  first think another disney movie might good it...          1\n",
       "1  put aside dr house repeat missed desperate hou...          0\n",
       "2  big fan stephen king s work film made even gre...          1\n",
       "3  watched horrid thing tv needless say one movie...          0\n",
       "4  truly enjoyed film acting terrific plot jeff c...          1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"../../../DataSets/IMDB_Cleaned/clean_data.csv\"\n",
    "df = pd.read_csv(data_path, index_col=[0])\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    12500\n",
       "0    12500\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 641.0, 873.35696, 9449)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_len = df['SentimentText'].apply(len)\n",
    "min(text_len), np.median(text_len), np.mean(text_len), max(text_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x1a2378f710>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['TextLength'] = text_len\n",
    "df.hist('TextLength')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pandas.core.series.Series, pandas.core.series.Series)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the input and output variable \n",
    "X=df.SentimentText\n",
    "y=df.Sentiment\n",
    "type(X), type(y)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tokenize the reviews \n",
    "Here, by applying tokenizer, we are ensuring that we want to\n",
    "consider a maximum 10,000-word vocabulary. For unseen words, we use a\n",
    "default token.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pandas.core.series.Series,\n",
       " (25000,),\n",
       " 0    first think another disney movie might good it...\n",
       " 1    put aside dr house repeat missed desperate hou...\n",
       " 2    big fan stephen king s work film made even gre...\n",
       " Name: SentimentText, dtype: object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X), X.shape, X[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the reviews \n",
    "tokenizer=Tokenizer(num_words=10000,oov_token='xxxxxxx')\n",
    "#tokenizer=Tokenizer(oov_token='xxxxxxx')\n",
    "# fit on the input data \n",
    "tokenizer.fit_on_texts(X)\n",
    "X_dict=tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74120, 74120)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_dict), len(list(enumerate(X_dict.items())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, ('xxxxxxx', 1)),\n",
       " (1, ('s', 2)),\n",
       " (2, ('movie', 3)),\n",
       " (3, ('film', 4)),\n",
       " (4, ('not', 5)),\n",
       " (5, ('it', 6)),\n",
       " (6, ('one', 7)),\n",
       " (7, ('like', 8)),\n",
       " (8, ('i', 9)),\n",
       " (9, ('good', 10))]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(X_dict.items()))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 \n",
      "*** [26, 32, 80, 746, 3, 151, 10, 6, 2, 270, 3, 36, 6, 94, 5, 259, 278, 6, 2020, 46, 3, 26, 134, 3, 76, 221, 58, 46, 6, 1571, 3183, 818, 21, 213, 90, 56, 1283, 3234, 559, 323, 90, 1035, 1, 784, 3657, 2378, 94, 5, 259, 278, 3, 119] \n",
      "---\n",
      "83 \n",
      "*** [194, 1137, 794, 226, 3159, 965, 1606, 9907, 81, 36, 7, 20, 5, 52, 541, 8290, 3, 45, 114, 9, 122, 60, 51, 99, 147, 2165, 69, 144, 387, 94, 5, 60, 3818, 9484, 77, 11, 564, 2967, 114, 6579, 5028, 627, 1507, 1746, 10, 869, 427, 331, 276, 1, 769, 436, 454, 962, 155, 86, 1, 1388, 4251, 1, 4018, 11, 1146, 9, 122, 8, 200, 3396, 295, 2631, 6, 2, 14, 4252, 2, 13, 59, 3879, 20, 5, 19, 13, 360] \n",
      "---\n",
      "200 \n",
      "*** [111, 254, 1584, 538, 2, 79, 4, 28, 14, 2729, 254, 538, 2824, 8796, 1, 130, 1609, 81, 226, 228, 565, 2824, 5949, 417, 226, 1, 2, 81, 3235, 1, 172, 1696, 1, 2476, 7553, 1483, 417, 2824, 5949, 7553, 1483, 972, 366, 1, 636, 2211, 1, 9103, 324, 434, 159, 2824, 7553, 1483, 12, 132, 69, 42, 362, 132, 69, 326, 208, 73, 366, 438, 1, 2476, 205, 2824, 8796, 205, 439, 64, 527, 4193, 1189, 1563, 20, 5, 99, 119, 161, 211, 454, 4, 44, 2824, 8796, 101, 10, 810, 47, 142, 79, 15, 7, 211, 454, 3, 1357, 118, 3057, 4, 856, 695, 30, 178, 220, 30, 3, 29, 3204, 2459, 7, 1042, 925, 3, 1350, 5339, 69, 108, 30, 178, 220, 7, 34, 4, 289, 6424, 34, 1, 764, 34, 4627, 4, 207, 127, 7139, 1, 2528, 1, 2, 675, 2042, 161, 76, 630, 2528, 58, 2265, 262, 26, 13, 1, 662, 3, 49, 5, 1147, 546, 49, 5, 577, 148, 253, 13, 165, 1126, 253, 13, 2529, 504, 140, 351, 82, 276, 3, 135, 323, 2824, 8796, 1472, 27, 2529, 101, 10, 44, 26, 883, 43, 5950, 30, 178, 289, 7, 436, 105, 38, 13] \n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# convert the reviews into sequences of word indexes \n",
    "X_seq=tokenizer.texts_to_sequences(X)\n",
    "for x in X_seq[:3]:\n",
    "    print(len(x),'\\n***', x, \"\\n---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_padded_seq:  <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  26,   32,   80,  746,    3,  151,   10,    6,    2,  270,    3,\n",
       "          36,    6,   94,    5,  259,  278,    6, 2020,   46,    3,   26,\n",
       "         134,    3,   76,  221,   58,   46,    6, 1571, 3183,  818,   21,\n",
       "         213,   90,   56, 1283, 3234,  559,  323,   90, 1035,    1,  784,\n",
       "        3657, 2378,   94,    5,  259,  278,    3,  119,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0],\n",
       "       [ 194, 1137,  794,  226, 3159,  965, 1606, 9907,   81,   36,    7,\n",
       "          20,    5,   52,  541, 8290,    3,   45,  114,    9,  122,   60,\n",
       "          51,   99,  147, 2165,   69,  144,  387,   94,    5,   60, 3818,\n",
       "        9484,   77,   11,  564, 2967,  114, 6579, 5028,  627, 1507, 1746,\n",
       "          10,  869,  427,  331,  276,    1,  769,  436,  454,  962,  155,\n",
       "          86,    1, 1388, 4251,    1, 4018,   11, 1146,    9,  122,    8,\n",
       "         200, 3396,  295, 2631,    6,    2,   14, 4252,    2,   13,   59,\n",
       "        3879,   20,    5,   19,   13,  360,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0],\n",
       "       [1357,  118, 3057,    4,  856,  695,   30,  178,  220,   30,    3,\n",
       "          29, 3204, 2459,    7, 1042,  925,    3, 1350, 5339,   69,  108,\n",
       "          30,  178,  220,    7,   34,    4,  289, 6424,   34,    1,  764,\n",
       "          34, 4627,    4,  207,  127, 7139,    1, 2528,    1,    2,  675,\n",
       "        2042,  161,   76,  630, 2528,   58, 2265,  262,   26,   13,    1,\n",
       "         662,    3,   49,    5, 1147,  546,   49,    5,  577,  148,  253,\n",
       "          13,  165, 1126,  253,   13, 2529,  504,  140,  351,   82,  276,\n",
       "           3,  135,  323, 2824, 8796, 1472,   27, 2529,  101,   10,   44,\n",
       "          26,  883,   43, 5950,   30,  178,  289,    7,  436,  105,   38,\n",
       "          13]], dtype=int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Max length of SentimentText\n",
    "MAX_LEN = 100\n",
    "# Pad sequences to max SentimentText length\n",
    "X_padded_seq=pad_sequences(X_seq,padding='post',maxlen=MAX_LEN)\n",
    "print(\"X_padded_seq: \", type(X_padded_seq))\n",
    "X_padded_seq[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 100)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_padded_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert y to NumPy array for TF to train\n",
    "y = np.array(y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test_validation, y_train, y_test_validation = \\\n",
    "train_test_split(X_padded_seq, y, test_size=0.3, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_validation, y_test, y_validation = \\\n",
    "train_test_split(X_test_validation, y_test_validation, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train, y_train: 17500 17500\n",
      "X_test, y_test  : 5625 5625\n",
      "X_validation, y_validation: 1875 1875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(25000, 25000)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"X_train, y_train:\", len(X_train), len(y_train))\n",
    "print(\"X_test, y_test  :\", len(X_test), len(y_test))\n",
    "print(\"X_validation, y_validation:\", len(X_validation), len(y_validation))\n",
    "len(X_train)+len(X_test)+len(X_validation), len(y_train)+len(y_test)+len(y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.keras.layers.embeddings.Embedding"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.layers.Embedding"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Build Model\n",
    "- input_length: Length of input sequences, when it is constant.\n",
    "    This argument is required if you are going to connect\n",
    "    `Flatten` then `Dense` layers upstream\n",
    "    (without it, the shape of the dense outputs cannot be computed).\n",
    "\n",
    "- input_dim: Integer. Size of the vocabulary, i.e. maximum integer index + 1.\n",
    "- output_dim: Integer. Dimension of the dense embedding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 100, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 30000)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 180006    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 3,180,013\n",
      "Trainable params: 3,180,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "text_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_length=MAX_LEN,input_dim=VOCAB_SIZE,\n",
    "                              output_dim=EMBEDDING_DIMS),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(6, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "text_model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "text_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?text_model.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "547/547 [==============================] - 13s 24ms/step - loss: 0.4436 - accuracy: 0.7694 - val_loss: 0.3393 - val_accuracy: 0.8459\n",
      "Epoch 2/10\n",
      "547/547 [==============================] - 11s 20ms/step - loss: 0.0868 - accuracy: 0.9717 - val_loss: 0.4122 - val_accuracy: 0.8416\n",
      "Epoch 3/10\n",
      "547/547 [==============================] - 11s 20ms/step - loss: 0.0073 - accuracy: 0.9993 - val_loss: 0.4468 - val_accuracy: 0.8507\n",
      "Epoch 4/10\n",
      "547/547 [==============================] - 11s 21ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4769 - val_accuracy: 0.8528\n",
      "Epoch 5/10\n",
      "547/547 [==============================] - 11s 20ms/step - loss: 5.3101e-04 - accuracy: 1.0000 - val_loss: 0.5006 - val_accuracy: 0.8528\n",
      "Epoch 6/10\n",
      "547/547 [==============================] - 11s 20ms/step - loss: 3.2918e-04 - accuracy: 1.0000 - val_loss: 0.5326 - val_accuracy: 0.8533\n",
      "Epoch 7/10\n",
      "547/547 [==============================] - 14s 25ms/step - loss: 2.1153e-04 - accuracy: 1.0000 - val_loss: 0.5663 - val_accuracy: 0.8491\n",
      "Epoch 8/10\n",
      "547/547 [==============================] - 14s 26ms/step - loss: 1.4152e-04 - accuracy: 1.0000 - val_loss: 0.5612 - val_accuracy: 0.8523\n",
      "Epoch 9/10\n",
      "547/547 [==============================] - 13s 24ms/step - loss: 8.6605e-05 - accuracy: 1.0000 - val_loss: 0.5788 - val_accuracy: 0.8523\n",
      "Epoch 10/10\n",
      "547/547 [==============================] - 13s 23ms/step - loss: 6.2951e-05 - accuracy: 1.0000 - val_loss: 0.5987 - val_accuracy: 0.8523\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "num_epochs = 10\n",
    "history = text_model.fit(X_train,y_train,validation_data=(X_validation, y_validation), epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 [==============================] - 1s 1ms/step - loss: 4.5040e-05 - accuracy: 1.0000\n",
      "Training Data Accuracy 1.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on training set\n",
    "training_loss, training_accuracy = text_model.evaluate(X_train, y_train)\n",
    "print('Training Data Accuracy {}'.format(round(float(training_accuracy),2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 1ms/step - loss: 0.5411 - accuracy: 0.8718\n",
      "Test Data Accuracy 0.87\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on a test set\n",
    "test_loss, test_accuracy = text_model.evaluate(X_test, y_test)\n",
    "print('Test Data Accuracy {}'.format(round(float(test_accuracy),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 0s 1ms/step - loss: 0.5987 - accuracy: 0.8523\n",
      "Validation Data Accuracy 0.85\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on validation set\n",
    "validation_loss, validation_accuracy = text_model.evaluate(X_validation, y_validation)\n",
    "print('Validation Data Accuracy {}'.format(round(float(validation_accuracy),2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?text_model.predict_classes # depricated\n",
    "y_test_pred=(text_model.predict(X_test) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 0]),\n",
       " array([[0],\n",
       "        [1],\n",
       "        [0]], dtype=int32))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:3], y_test_pred[:3]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "By definition a confusion matrix C is such that  C(i,j) is equal to the number of observations known to be in group i and predicted to be in group j.\n",
    "\n",
    "Thus in binary classification, the count of true negatives is C(0,0), false negatives is C(\n",
    "1,0), true positives is C(1,1) and false positives is C(0,1).\n",
    "\n",
    "TN FP\n",
    "FN TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.42737778, 0.07075556],\n",
       "       [0.05742222, 0.44444444]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_test_pred, normalize='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2404, 398, 323, 2500)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87      2802\n",
      "           1       0.86      0.89      0.87      2823\n",
      "\n",
      "    accuracy                           0.87      5625\n",
      "   macro avg       0.87      0.87      0.87      5625\n",
      "weighted avg       0.87      0.87      0.87      5625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "#target_names = ['class 0', 'class 1', 'class 2']\n",
    "#print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "plot_confusion_matrix(clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.keras.layers.embeddings.Embedding"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Embedding layer\n",
    "embeddings = text_model.layers[0]\n",
    "type(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'embedding/embeddings:0' shape=(10000, 300) dtype=float32, numpy=\n",
       " array([[ 5.2797738e-03, -2.0149841e-03, -9.8722838e-03, ...,\n",
       "         -1.4384610e-02,  7.6469751e-03, -1.9634791e-02],\n",
       "        [ 4.0289327e-03,  9.6776971e-04, -3.9449293e-02, ...,\n",
       "          5.9973899e-02, -4.0103545e-04, -6.1077889e-02],\n",
       "        [-4.9367961e-03,  2.8243951e-02, -5.9140433e-02, ...,\n",
       "          2.8827634e-02, -1.3600631e-02, -5.6150720e-02],\n",
       "        ...,\n",
       "        [ 8.7362053e-03, -2.6489742e-02, -7.5121680e-03, ...,\n",
       "         -3.3257627e-05, -1.3329565e-02,  3.3535693e-02],\n",
       "        [-3.9120413e-02,  1.4485537e-02, -9.6949860e-02, ...,\n",
       "          1.3178653e-02,  8.1178226e-02,  2.3013251e-02],\n",
       "        [-4.9871914e-03, -4.1323293e-02, -3.0039050e-02, ...,\n",
       "         -2.4158822e-02,  1.0478832e-02,  1.3653833e-02]], dtype=float32)>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'embedding/embeddings:0' shape=(10000, 300) dtype=float32, numpy=\n",
       "array([[ 5.2797738e-03, -2.0149841e-03, -9.8722838e-03, ...,\n",
       "        -1.4384610e-02,  7.6469751e-03, -1.9634791e-02],\n",
       "       [ 4.0289327e-03,  9.6776971e-04, -3.9449293e-02, ...,\n",
       "         5.9973899e-02, -4.0103545e-04, -6.1077889e-02],\n",
       "       [-4.9367961e-03,  2.8243951e-02, -5.9140433e-02, ...,\n",
       "         2.8827634e-02, -1.3600631e-02, -5.6150720e-02],\n",
       "       ...,\n",
       "       [ 8.7362053e-03, -2.6489742e-02, -7.5121680e-03, ...,\n",
       "        -3.3257627e-05, -1.3329565e-02,  3.3535693e-02],\n",
       "       [-3.9120413e-02,  1.4485537e-02, -9.6949860e-02, ...,\n",
       "         1.3178653e-02,  8.1178226e-02,  2.3013251e-02],\n",
       "       [-4.9871914e-03, -4.1323293e-02, -3.0039050e-02, ...,\n",
       "        -2.4158822e-02,  1.0478832e-02,  1.3653833e-02]], dtype=float32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (10000, 300))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get word embedding vectors\n",
    "weights = embeddings.get_weights()[0]\n",
    "type(weights), weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dict(key=word, val=index) into dict(key=index, value=word) \n",
    "index_based_embedding  = dict([(value, key) for (key, value) in X_dict.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxxxxxx'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_based_embedding[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.02893266e-03,  9.67769709e-04, -3.94492932e-02,  3.59493233e-02,\n",
       "       -2.97283828e-02,  5.53149311e-03,  2.27894471e-03, -2.25645918e-02,\n",
       "       -1.64849926e-02, -4.17191871e-02,  8.28151479e-02,  2.84344759e-02,\n",
       "       -3.47646289e-02, -3.16785561e-04, -4.22985107e-02, -2.00995896e-02,\n",
       "        3.39153372e-02, -5.99438623e-02,  9.29054525e-03, -2.17801202e-02,\n",
       "        1.88601818e-02,  1.01975892e-02, -2.79457867e-02, -3.60255204e-02,\n",
       "       -3.42316218e-02,  8.36537313e-03, -3.16716358e-02,  1.40266251e-02,\n",
       "        2.81665679e-02,  2.30744649e-02,  6.45193830e-02, -9.52681340e-03,\n",
       "        1.34972502e-02,  3.00974064e-02, -2.83709578e-02, -9.08830483e-03,\n",
       "       -3.06926537e-02, -1.33489957e-02, -1.53489993e-03, -1.63996257e-02,\n",
       "       -1.26455899e-03,  2.74262880e-03, -2.98254117e-02, -1.63023192e-02,\n",
       "       -4.39140275e-02,  8.76023099e-02, -1.49990572e-02,  6.31122291e-03,\n",
       "        3.67901288e-02, -3.76219340e-02, -3.40063404e-03, -5.57438731e-02,\n",
       "        3.67524549e-02, -1.41035905e-02,  1.36193549e-02, -1.62707809e-02,\n",
       "        1.71866156e-02,  3.93494358e-03, -4.45241667e-02, -5.68320826e-02,\n",
       "       -1.44460127e-02, -1.44561715e-02, -6.75477386e-02,  2.53142230e-02,\n",
       "       -4.85678464e-02, -5.05539514e-02,  5.61458878e-02, -3.81094664e-02,\n",
       "       -1.65440813e-02, -9.85702965e-03,  2.49547772e-02,  3.09472512e-02,\n",
       "        6.33237511e-02,  4.95262817e-02, -6.46425225e-03, -1.60036646e-02,\n",
       "       -2.67543048e-02,  3.14779580e-02, -1.38620446e-02, -2.69989949e-02,\n",
       "        3.20467651e-02,  5.19613959e-02,  1.04708225e-02,  1.83191597e-02,\n",
       "       -5.53268660e-03,  1.16196657e-02,  5.01278974e-02,  3.77146192e-02,\n",
       "       -2.72304448e-03, -7.24064708e-02,  6.20420352e-02,  3.65792923e-02,\n",
       "        6.80313632e-03, -2.35440060e-02, -2.00194269e-02, -6.95652561e-03,\n",
       "        2.18698345e-02, -5.32874651e-03,  4.52889391e-04,  5.17865159e-02,\n",
       "        3.36647369e-02,  4.51804213e-02, -2.20248904e-02, -4.63705175e-02,\n",
       "       -7.64685348e-02, -4.70063053e-02, -1.99321122e-03,  6.94186687e-02,\n",
       "       -7.45652989e-02,  3.11151464e-02, -5.38059510e-02,  3.95469368e-02,\n",
       "       -4.05289792e-02,  4.91752662e-02,  2.61603054e-02, -1.13723800e-02,\n",
       "        3.31212953e-02,  4.71250638e-02, -6.50099367e-02, -4.80494974e-03,\n",
       "       -3.37865227e-03, -8.30210075e-02,  2.66976524e-02, -3.47297601e-02,\n",
       "       -2.75334865e-02,  6.99651148e-03, -1.23775110e-03, -3.84477563e-02,\n",
       "        6.28505088e-03,  1.16889467e-02, -4.54528667e-02, -2.47464627e-02,\n",
       "        3.76898795e-02,  3.78376767e-02,  3.47992103e-03, -7.12098368e-03,\n",
       "       -3.46580781e-02,  8.48941803e-02, -9.40338243e-04, -3.39861773e-02,\n",
       "        8.28241706e-02,  4.56503630e-02,  3.89778637e-03,  2.68004015e-02,\n",
       "       -1.03111984e-02,  2.55904756e-02, -6.25160038e-02, -1.39705688e-02,\n",
       "        3.64336632e-02, -3.38724139e-03,  2.67164665e-03,  2.00206786e-02,\n",
       "        3.40359583e-02,  3.44910137e-02,  5.17943117e-05, -2.07065754e-02,\n",
       "        3.64505351e-02,  7.32700294e-03,  4.74914722e-02,  2.61577722e-02,\n",
       "       -3.76334675e-02,  5.43272607e-02,  5.83923943e-02,  5.79496399e-02,\n",
       "        5.54747041e-03, -1.91525593e-02,  1.59947835e-02,  2.62620430e-02,\n",
       "       -4.45684865e-02,  7.52945393e-02, -6.79505542e-02,  3.15277763e-02,\n",
       "        4.35359180e-02,  7.26208370e-03,  3.08204908e-02, -3.35090794e-03,\n",
       "       -5.17801903e-02,  1.52064301e-02, -2.41511930e-02, -2.83126701e-02,\n",
       "        6.91370592e-02, -4.41184361e-03,  7.27727413e-02, -3.82072888e-02,\n",
       "       -3.40861827e-02,  2.81704087e-02, -2.36678049e-02, -1.29706208e-02,\n",
       "       -5.19402623e-02,  8.38118885e-03, -2.63727158e-02,  6.35771975e-02,\n",
       "       -1.55083686e-02,  1.00744050e-02,  1.29303290e-02,  5.71224727e-02,\n",
       "       -6.54123351e-02,  5.17014265e-02, -1.63777284e-02, -3.45154740e-02,\n",
       "        5.08768447e-02,  4.84475605e-02, -1.37127833e-02,  4.50199321e-02,\n",
       "       -3.83153632e-02,  1.54814748e-02,  2.63528004e-02,  5.86345233e-03,\n",
       "        7.40345269e-02,  3.53442170e-02,  1.42551847e-02, -1.01705277e-02,\n",
       "        1.22053698e-02,  1.31487567e-02, -3.54896262e-02,  6.26328140e-02,\n",
       "        4.11762595e-02,  6.31879270e-02,  3.34646627e-02, -2.26693712e-02,\n",
       "       -6.20177500e-02,  5.99341132e-02, -2.18921937e-02,  1.06154592e-03,\n",
       "       -9.50031262e-03,  4.68668714e-02, -7.08298460e-02,  3.27377133e-02,\n",
       "       -3.23140584e-02, -2.69222129e-02,  4.06502970e-02, -2.24180538e-02,\n",
       "       -2.25204253e-03, -4.37779119e-03, -9.33164638e-03, -2.06142152e-03,\n",
       "        1.18653299e-02,  7.16575189e-03,  5.31592630e-02, -1.00316465e-01,\n",
       "       -1.04279853e-01, -2.57391967e-02, -3.74015374e-03,  3.82810235e-02,\n",
       "        3.04711983e-02, -3.76949050e-02, -7.91577995e-03,  5.11596259e-03,\n",
       "       -8.55155941e-03, -3.37579176e-02,  2.11290289e-02,  8.55789334e-03,\n",
       "        1.87549368e-03,  2.39318749e-03, -1.06198348e-01,  4.95228805e-02,\n",
       "       -4.42834618e-03, -2.56665964e-02,  6.10506460e-02,  1.95642244e-02,\n",
       "        2.77136862e-02, -6.15346758e-03, -3.31830001e-03,  6.12533018e-02,\n",
       "       -3.34253721e-02, -3.64666171e-02,  5.82827954e-03, -5.19342385e-02,\n",
       "        5.30768670e-02,  2.06975220e-03, -9.16843116e-03,  4.07888591e-02,\n",
       "        6.66479319e-02, -5.36436625e-02, -5.99304698e-02,  4.08150144e-02,\n",
       "       -7.09075155e-03,  5.37725165e-03,  4.96056378e-02, -1.63102627e-03,\n",
       "        1.69576015e-02, -7.20474124e-02,  1.68478638e-02,  1.21893678e-02,\n",
       "       -2.57057827e-02, -2.82994658e-02, -4.53713313e-02,  2.78591644e-02,\n",
       "        6.26117736e-02,  1.14302700e-02, -5.65531701e-02,  3.03157885e-03,\n",
       "       -3.77527699e-02,  2.94612907e-03,  1.25759039e-02, -3.07611469e-02,\n",
       "       -1.11176167e-02,  5.99738993e-02, -4.01035446e-04, -6.10778891e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write words and corresponding embedding vectors into files \n",
    "vec = io.open('embedding_vectors_new.tsv', 'w', encoding='utf-8')\n",
    "meta = io.open('metadata_new.tsv', 'w', encoding='utf-8')\n",
    "for i in range(1, VOCAB_SIZE):\n",
    "    word = index_based_embedding[i]\n",
    "    embedding_vec_values = weights[i]\n",
    "    meta.write(word + \"\\n\")\n",
    "    v = '\\t'.join([str(x) for x in embedding_vec_values]) + \"\\n\"\n",
    "    #print(v)\n",
    "    vec.write(v)\n",
    "meta.close()\n",
    "vec.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find words similar to the selected one\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97463185, 1.        , 0.97463185]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1,2,3]])\n",
    "y = np.array([[4,5,6],[1,2,3],[4,5,6]])\n",
    "cosine_similarity(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'xxxxxxx'),\n",
       " (2, 's'),\n",
       " (3, 'movie'),\n",
       " (4, 'film'),\n",
       " (5, 'not'),\n",
       " (6, 'it'),\n",
       " (7, 'one'),\n",
       " (8, 'like'),\n",
       " (9, 'i'),\n",
       " (10, 'good'),\n",
       " (11, 'the'),\n",
       " (12, 'would'),\n",
       " (13, 'time'),\n",
       " (14, 'even'),\n",
       " (15, 'story'),\n",
       " (16, 'really'),\n",
       " (17, 'see'),\n",
       " (18, 'well'),\n",
       " (19, 'much')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i,index_based_embedding[i]) for i in range(1,20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74120, 10000)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have more words then embedding vectors?\n",
    "len(index_based_embedding),len(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index:  10 word:  good\n",
      "embedding vector:  [array([-0.01680839, -0.02512935, -0.0579353 ,  0.01819934, -0.0112552 ,\n",
      "        0.05293313,  0.05660734, -0.09103775, -0.01854282, -0.0613924 ,\n",
      "        0.00435629,  0.03235607,  0.05664624, -0.06959596,  0.00551949,\n",
      "        0.06763465,  0.0074096 , -0.01954271, -0.00494357,  0.00844912,\n",
      "       -0.01790668, -0.07425825, -0.05328366,  0.08472874,  0.09772804,\n",
      "       -0.05000933, -0.00036896,  0.0794009 ,  0.00848361, -0.01336526,\n",
      "       -0.06298934, -0.07108374, -0.02365655, -0.04610411,  0.03476822,\n",
      "        0.00141685, -0.03847143,  0.02549381,  0.07655305, -0.0127051 ,\n",
      "       -0.02123689, -0.0667702 , -0.01036906,  0.04975012, -0.04628154,\n",
      "        0.00609075, -0.04458419,  0.06490424, -0.04230119, -0.06674407,\n",
      "       -0.08292507,  0.05645886,  0.04818033, -0.02400586, -0.04288796,\n",
      "       -0.05529999,  0.04924598, -0.01287612,  0.08042385,  0.04797852,\n",
      "       -0.04856018, -0.02629248, -0.01637704,  0.03404662, -0.04213558,\n",
      "       -0.07492184, -0.07415196, -0.0246409 ,  0.06388538, -0.02755143,\n",
      "        0.08526392, -0.04224716,  0.0351973 ,  0.02741057, -0.0232552 ,\n",
      "       -0.11090258, -0.02229031, -0.05500383, -0.03051718,  0.07487282,\n",
      "       -0.00964891, -0.07076625, -0.01803092, -0.07837901,  0.05222416,\n",
      "        0.00636999, -0.02856959,  0.01122026,  0.05215932, -0.0638563 ,\n",
      "       -0.00602187,  0.02406744,  0.07288866,  0.00856675, -0.02159206,\n",
      "        0.02251854,  0.10984328,  0.00690511, -0.0315902 ,  0.01766486,\n",
      "        0.0652533 , -0.00752847,  0.04658648, -0.07136464, -0.06053929,\n",
      "        0.06210521,  0.03005818, -0.04575479, -0.0306604 , -0.02696428,\n",
      "        0.05214621,  0.02022136,  0.04842369,  0.02479133, -0.06055129,\n",
      "        0.01405726,  0.00313829, -0.04403039, -0.00950364,  0.06830408,\n",
      "        0.00253299, -0.04885617,  0.0356815 , -0.00304404,  0.00571303,\n",
      "       -0.0984969 ,  0.09438261, -0.06246243,  0.05277291,  0.07376023,\n",
      "        0.05083233,  0.04266561, -0.00597499,  0.01836912,  0.08183992,\n",
      "       -0.06761305, -0.0023753 , -0.01189473,  0.02401343, -0.07472336,\n",
      "        0.02686558,  0.09421857,  0.04010613,  0.01222163, -0.02841992,\n",
      "        0.04273018,  0.00836434,  0.00669245,  0.0446154 ,  0.01886846,\n",
      "        0.03801978,  0.03501873,  0.02343312,  0.0534765 ,  0.03099876,\n",
      "       -0.05736551, -0.02314258,  0.01799064,  0.01492642,  0.0125415 ,\n",
      "       -0.05602885,  0.00307475, -0.01080545, -0.09354898, -0.00215047,\n",
      "       -0.05755373,  0.09819545,  0.01170014,  0.00292934, -0.00814593,\n",
      "       -0.02926561,  0.02801322,  0.00110455,  0.0182141 , -0.05295498,\n",
      "       -0.01881652, -0.07658704,  0.0406912 ,  0.01841943,  0.09107044,\n",
      "        0.07764561,  0.08556987,  0.09324143,  0.01773329, -0.06892691,\n",
      "       -0.07624111, -0.00248012,  0.06142615,  0.01770514,  0.04777452,\n",
      "        0.05300641,  0.02562167,  0.07620756, -0.02038409,  0.04716333,\n",
      "        0.05276848, -0.00913201,  0.04911498,  0.02214365, -0.00976624,\n",
      "        0.06782778,  0.01050133,  0.02269654, -0.01344476,  0.05726628,\n",
      "        0.01104175,  0.03627403,  0.06093707, -0.00745425, -0.12093471,\n",
      "       -0.0043447 ,  0.08981113, -0.08733539, -0.06802331, -0.02834238,\n",
      "        0.04159525,  0.02926653, -0.0485894 , -0.00145155, -0.10968347,\n",
      "        0.03628284,  0.08647382, -0.14683099, -0.00353294, -0.01723482,\n",
      "       -0.02724155, -0.00076976, -0.03245765, -0.12941024, -0.01113546,\n",
      "       -0.07768385, -0.02372758,  0.01043164,  0.04288982,  0.05566789,\n",
      "       -0.03088272, -0.03018118, -0.01811482, -0.01601786, -0.06165849,\n",
      "       -0.02986416,  0.04381634, -0.01780825,  0.01018716, -0.0896912 ,\n",
      "        0.00405152, -0.05921629,  0.02027632,  0.02054293, -0.03680697,\n",
      "       -0.00861162, -0.03433751, -0.00947184,  0.05643481,  0.01918338,\n",
      "       -0.01722839,  0.00959296,  0.00956784,  0.00209562, -0.01388904,\n",
      "       -0.04687626, -0.08119144,  0.04242634, -0.08655293, -0.07302282,\n",
      "        0.02983858, -0.05422338,  0.04893378,  0.04581358,  0.09082782,\n",
      "        0.01522702,  0.01445574, -0.0290352 , -0.01581677,  0.11504593,\n",
      "        0.02342738,  0.01553741, -0.05449357,  0.02866315,  0.05060194,\n",
      "       -0.0558622 , -0.06907149,  0.02911919,  0.05545689,  0.0227297 ,\n",
      "       -0.06418521, -0.00193264, -0.00065192, -0.01959465,  0.02732123,\n",
      "       -0.11724421, -0.00371118,  0.05455386, -0.03982304,  0.05543361,\n",
      "       -0.01646633,  0.02355888,  0.00616968,  0.07981607,  0.00480649],\n",
      "      dtype=float32)]\n",
      " (1, 10000)\n"
     ]
    }
   ],
   "source": [
    "# Find words similar to word with index = 10\n",
    "word_ind = 10\n",
    "x = [weights[word_ind]]\n",
    "print(\"index: \", word_ind, \"word: \", index_based_embedding[word_ind])\n",
    "print(\"embedding vector: \",x)\n",
    "similarity = cosine_similarity(x,weights)\n",
    "print(\"\",similarity.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.06544521,  0.0866065 ,  0.23919728, ...,  0.12840417,\n",
       "        0.36495095, -0.3121783 ], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, -0.065445215),\n",
       " (1, 0.0866065),\n",
       " (2, 0.23919728),\n",
       " (3, 0.07911025),\n",
       " (4, 0.22877207),\n",
       " (5, -0.12439906),\n",
       " (6, 0.24453272),\n",
       " (7, 0.15536298),\n",
       " (8, 0.05160991),\n",
       " (9, -0.012487527)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add word index to cos (similarity) with other vectors\n",
    "similarity_with_index = list(enumerate(similarity[0]))\n",
    "similarity_with_index[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10, 0.9999999),\n",
       " (3047, 0.54786146),\n",
       " (1369, 0.53376997),\n",
       " (3176, 0.53078675),\n",
       " (2271, 0.5214392),\n",
       " (453, 0.51638126),\n",
       " (470, 0.5145678),\n",
       " (7231, 0.51353836),\n",
       " (1366, 0.5132502),\n",
       " (649, 0.5110544)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort by cos value\n",
    "similarity_with_index.sort(reverse=True, key = lambda x: x[1])  \n",
    "similarity_with_index[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n",
      "guessing\n",
      "emotions\n",
      "unforgettable\n",
      "captures\n",
      "brilliant\n",
      "highly\n",
      "blaise\n",
      "fascinating\n",
      "moving\n",
      "blake\n",
      "absorbing\n",
      "fuller\n",
      "excellent\n",
      "greatest\n",
      "perfectly\n",
      "chilling\n",
      "finest\n",
      "challenge\n",
      "superb\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(index_based_embedding[similarity_with_index[i][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***  0 1\n",
      "***  0.0866065 2\n",
      "***  0.23919728 6\n",
      "***  0.24453272 18\n",
      "***  0.38943762 27\n",
      "***  0.42830217 46\n",
      "***  0.43276167 86\n",
      "***  0.47978753 240\n",
      "***  0.5047103 453\n",
      "***  0.51638126 1369\n",
      "***  0.53376997 3047\n"
     ]
    }
   ],
   "source": [
    "# Alternative way to find best cos\n",
    "best_cos = 0\n",
    "best_index = 0\n",
    "for i,cos in enumerate(similarity[0]):\n",
    "    #print(\"--- \",cos, i)\n",
    "    if cos > best_cos and i != word_ind:\n",
    "        print(\"*** \",best_cos, i)\n",
    "        best_cos = cos\n",
    "        best_index = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_cos: 0.5478614568710327 best_index: 3047\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('good', 'coup')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"best_cos: {} best_index: {}\".format(best_cos, best_index))\n",
    "index_based_embedding[word_ind], index_based_embedding[5707]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.54786146, 3047)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_cos, best_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
