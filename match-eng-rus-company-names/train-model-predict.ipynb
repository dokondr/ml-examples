{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification with Muse Emebedding (Vector Average)\n",
    "## Contents:\n",
    "1. Load Muse Embiddings\n",
    "2. Convert tokenized documents to the embedding vectors calculted by averaging\n",
    "3. Build Simple Keras Model\n",
    "4. Train and evaluate\n",
    "5. Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform\n",
    "import os\n",
    "import tensorflow as tf\n",
    "#disable warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EN_VEC = \"./muse_embeddings/wiki.multi.en.vec\"\n",
    "RU_VEC = \"./muse_embeddings/wiki.multi.ru.vec\"\n",
    "CLEAN_TRAIN_DATA = \"clean_train_data.csv\"\n",
    "CLEAN_TEST_DATA = \"clean_test_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_muse_vecs(muse_file):\n",
    "    \"\"\" Reads the muse embedding vector file\n",
    "    \n",
    "        Args:\n",
    "            muse_file - embedding file name\n",
    "        \n",
    "        Returns:\n",
    "            words_to_index - words to index map \n",
    "            index_to_words - index to words map\n",
    "            word_to_vec_map - word to vector map\n",
    "    \"\"\"\n",
    "    with open(muse_file, 'r',  errors='ignore', encoding=\"utf-8\") as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word_list = line[0: len(line) - 300]\n",
    "            curr_word = \"\"\n",
    "            for t in curr_word_list:\n",
    "                curr_word = curr_word + str(t) + \" \"\n",
    "            curr_word = curr_word.strip()\n",
    "            words.add(curr_word)\n",
    "            try:\n",
    "                word_to_vec_map[curr_word] = np.array(line[-300:], dtype=np.float64)\n",
    "            except:\n",
    "                print(line, len(line))\n",
    "\n",
    "        i = 1\n",
    "        words_to_index = {}\n",
    "        index_to_words = {}\n",
    "\n",
    "        words.add(\"nokey\")\n",
    "        word_to_vec_map[\"nokey\"] = np.zeros((300,), dtype=np.float64)\n",
    "\n",
    "        for w in sorted(words):\n",
    "            words_to_index[w] = i\n",
    "            index_to_words[i] = w\n",
    "            i = i + 1\n",
    "    return words_to_index, index_to_words, word_to_vec_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def docs_to_vector(docs, vec_map):\n",
    "    \"\"\" Convert tokenized docs to vector embeddings by averaging\n",
    "    \n",
    "        Args:\n",
    "            docs - array of tokenized texts\n",
    "            vec_map - word to vector map\n",
    "            \n",
    "        Returns:\n",
    "            array of average vectors for every text\n",
    "            \n",
    "    \"\"\"\n",
    "    vectors = []\n",
    "    \n",
    "    for doc in docs:\n",
    "        vector = np.zeros((300,), dtype=np.float64)\n",
    "        for token in doc:\n",
    "            if token.lower() in vec_map:\n",
    "                vector += vec_map[token.lower()]\n",
    "            else:\n",
    "                vector += vec_map[\"nokey\"]\n",
    "        vector /= len(doc)\n",
    "        vectors.append(vector)\n",
    "    return np.array(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_one_hot(y, C):\n",
    "    \"\"\" Convert lables to one-hot vectors\n",
    "    \"\"\"\n",
    "    Y = np.eye(C)[y.reshape(-1)]\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3983203 entries, 0 to 3983202\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Dtype \n",
      "---  ------      ----- \n",
      " 0   Unnamed: 0  int64 \n",
      " 1   label       int64 \n",
      " 2   ru_tocks    object\n",
      " 3   eng_tocks   object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 121.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>ru_tocks</th>\n",
       "      <th>eng_tocks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>256257</th>\n",
       "      <td>256257</td>\n",
       "      <td>0</td>\n",
       "      <td>['зао', 'европа', 'ойл', 'пайп', 'сэпплай']</td>\n",
       "      <td>['pozitive', 'design', 'liability', 'limited',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015512</th>\n",
       "      <td>1015512</td>\n",
       "      <td>0</td>\n",
       "      <td>['акционерное', 'общество', 'транснед', 'групп']</td>\n",
       "      <td>['limited', 'liability', 'company', 'tv', 'com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998474</th>\n",
       "      <td>1998474</td>\n",
       "      <td>0</td>\n",
       "      <td>['гуп', 'краснодарского', 'края', 'кубаньпортс...</td>\n",
       "      <td>['dinara', 'jsc']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  label                                           ru_tocks  \\\n",
       "256257       256257      0        ['зао', 'европа', 'ойл', 'пайп', 'сэпплай']   \n",
       "1015512     1015512      0   ['акционерное', 'общество', 'транснед', 'групп']   \n",
       "1998474     1998474      0  ['гуп', 'краснодарского', 'края', 'кубаньпортс...   \n",
       "\n",
       "                                                 eng_tocks  \n",
       "256257   ['pozitive', 'design', 'liability', 'limited',...  \n",
       "1015512  ['limited', 'liability', 'company', 'tv', 'com...  \n",
       "1998474                                  ['dinara', 'jsc']  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(CLEAN_TRAIN_DATA)\n",
    "df.info()\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split all train data into train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3186562, 796641)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, validation = train_test_split(df, test_size=0.2)\n",
    "len(train), len(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                                               645976\n",
       "label                                                         0\n",
       "ru_tocks      ['общество', 'с', 'ограниченной', 'ответственн...\n",
       "eng_tocks        ['limited', 'liability', 'company', 'frigate']\n",
       "Name: 645976, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vectors(df, word_to_vec_map_eng, word_to_vec_map_ru):\n",
    "    \"\"\" Create vectors\n",
    "    \n",
    "        Args:\n",
    "            df - data frame with tokenized data set\n",
    "            word_to_vec_map_eng - English word to vector map \n",
    "            word_to_vec_map_ru - Russian word to vector map\n",
    "            \n",
    "        Returns:\n",
    "            vectors - concatenated average English and Russian vectors\n",
    "        \n",
    "    \"\"\"\n",
    "    eng_vectors = docs_to_vector(df['eng_tocks'].values, word_to_vec_map_eng)\n",
    "    ru_vectors = docs_to_vector(df['ru_tocks'].values, word_to_vec_map_ru)\n",
    "    vectors = np.concatenate((eng_vectors, ru_vectors), axis=1)\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create vectors for train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Muse  English Embeddings\n",
    "word_to_index_eng, index_to_words_eng, word_to_vec_map_eng = read_muse_vecs(\n",
    "    './muse_embeddings/wiki.multi.en.vec')\n",
    "# Load Muse Russian Embeddings\n",
    "word_to_index_ru, index_to_words_ru, word_to_vec_map_ru = read_muse_vecs(\n",
    "    './muse_embeddings/wiki.multi.ru.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectors = create_vectors(train, word_to_vec_map_eng, word_to_vec_map_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validation_vectors = create_vectors(validation, word_to_vec_map_eng, word_to_vec_map_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3186562, 600) (796641, 600)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_vectors.shape, X_validation_vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create one-hot label encoddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3186562, 2) (796641, 2)\n"
     ]
    }
   ],
   "source": [
    "y_train = train['label'].values\n",
    "y_train_oh = convert_to_one_hot(y_train, 2)\n",
    "y_validation = validation['label'].values\n",
    "y_validation_oh = convert_to_one_hot(y_validation, 2)\n",
    "print(y_train_oh.shape, y_validation_oh.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_model():\n",
    "    input_layer = Input(shape=(600,))\n",
    "    X = Dense(128)(input_layer)\n",
    "    X = Activation(\"relu\")(X)\n",
    "    X = Dense(2)(X)\n",
    "    X = Activation(\"softmax\")(X)\n",
    "    return Model(input=input_layer, output=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               76928     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 258       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 77,186\n",
      "Trainable params: 77,186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ac...)`\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "model = my_model()\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3186562 samples, validate on 796641 samples\n",
      "Epoch 1/4\n",
      "3186562/3186562 [==============================] - 2471s 775us/step - loss: 0.1778 - accuracy: 0.9542 - val_loss: 0.1646 - val_accuracy: 0.9539\n",
      "Epoch 2/4\n",
      "3186562/3186562 [==============================] - 2944s 924us/step - loss: 0.1535 - accuracy: 0.9552 - val_loss: 0.1543 - val_accuracy: 0.9550\n",
      "Epoch 3/4\n",
      "3186562/3186562 [==============================] - 3161s 992us/step - loss: 0.1414 - accuracy: 0.9568 - val_loss: 0.1407 - val_accuracy: 0.9570\n",
      "Epoch 4/4\n",
      "3186562/3186562 [==============================] - 3240s 1ms/step - loss: 0.1338 - accuracy: 0.9581 - val_loss: 0.1377 - val_accuracy: 0.9579\n",
      "CPU times: user 35min 18s, sys: 52min 37s, total: 1h 27min 56s\n",
      "Wall time: 3h 16min 59s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a58c96bd0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_vectors, y_train_oh, epochs = 4, batch_size = 32, shuffle=True, \n",
    "          validation_data=(X_validation_vectors, y_validation_oh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "# model.save('model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "#del model  # deletes the existing model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 996052 entries, 0 to 996051\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   ru_tocks   996052 non-null  object\n",
      " 1   eng_tocks  996052 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 22.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ru_tocks</th>\n",
       "      <th>eng_tocks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106271</th>\n",
       "      <td>['общество', 'с', 'ограниченной', 'ответственн...</td>\n",
       "      <td>['international', 'corporation', 'dzhun', 'kha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7387</th>\n",
       "      <td>['ооо', 'золотая', 'формулакаспий']</td>\n",
       "      <td>['duala', 'ooo']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227468</th>\n",
       "      <td>['общество', 'с', 'ограниченной', 'ответственн...</td>\n",
       "      <td>['limite', 'liability', 'company', 'belongs', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 ru_tocks  \\\n",
       "106271  ['общество', 'с', 'ограниченной', 'ответственн...   \n",
       "7387                  ['ооо', 'золотая', 'формулакаспий']   \n",
       "227468  ['общество', 'с', 'ограниченной', 'ответственн...   \n",
       "\n",
       "                                                eng_tocks  \n",
       "106271  ['international', 'corporation', 'dzhun', 'kha...  \n",
       "7387                                     ['duala', 'ooo']  \n",
       "227468  ['limite', 'liability', 'company', 'belongs', ...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(CLEAN_TEST_DATA, index_col=0)\n",
    "test.info()\n",
    "test.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create test vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_vectors = create_vectors(test, word_to_vec_map_eng, word_to_vec_map_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "# model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict classes and save predictions to 'result.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = model.predict(X_test_vectors) \n",
    "y_classes = y_prob.argmax(axis=-1)\n",
    "y_answers = [y > 0 for y in y_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 996052 entries, 0 to 996051\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count   Dtype\n",
      "---  ------  --------------   -----\n",
      " 0   answer  996052 non-null  bool \n",
      "dtypes: bool(1)\n",
      "memory usage: 972.8 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26397</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545236</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199878</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473507</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942847</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        answer\n",
       "26397    False\n",
       "545236   False\n",
       "199878   False\n",
       "473507   False\n",
       "942847   False"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(y_answers)\n",
    "result.columns = ['answer']\n",
    "result.info()\n",
    "result.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    989640\n",
       "True       6412\n",
       "Name: answer, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['answer'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('result.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
